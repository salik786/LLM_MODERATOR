{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from chatbot import *\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Bob! How can I assist you today?\n",
      "Your name is Bob. How can I help you today, Bob?\n"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "\n",
    "# Start a new conversation (thread) with thread_id 'abc123'\n",
    "thread_id = 'abc123'\n",
    "\n",
    "# Send messages to the chatbot\n",
    "response = chatbot.send_message(\"Hi! I'm Bob.\", thread_id=thread_id, language='English')\n",
    "print(response.content)\n",
    "\n",
    "# Continue the conversation\n",
    "response = chatbot.send_message(\"What's my name?\", thread_id=thread_id, language='English')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!"
     ]
    }
   ],
   "source": [
    "# Stream a response from the chatbot\n",
    "for chunk in chatbot.send_message_stream(\"Tell me a joke.\", thread_id=thread_id):\n",
    "    print(chunk.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.10-cp310-cp310-macosx_11_0_arm64.whl (455 kB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp310-cp310-macosx_12_0_arm64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading propcache-0.2.1-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-macosx_11_0_arm64.whl (92 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, numpy, multidict, fsspec, frozenlist, filelock, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 async-timeout-5.0.1 attrs-24.2.0 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.3 multidict-6.1.0 multiprocess-0.70.16 numpy-2.1.3 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pytz-2024.2 tzdata-2024.2 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizanfaisal/anaconda3/envs/edu_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 8548/8548 [00:00<00:00, 36026.59 examples/s]\n",
      "Generating validation split: 100%|██████████| 1025/1025 [00:00<00:00, 31602.65 examples/s]\n",
      "Generating test split: 100%|██████████| 1007/1007 [00:00<00:00, 35877.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"GEM/FairytaleQA\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story_name', 'content', 'answer', 'question', 'gem_id', 'target', 'references', 'local_or_sum', 'attribute', 'ex_or_im'],\n",
       "        num_rows: 8548\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['story_name', 'content', 'answer', 'question', 'gem_id', 'target', 'references', 'local_or_sum', 'attribute', 'ex_or_im'],\n",
       "        num_rows: 1025\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['story_name', 'content', 'answer', 'question', 'gem_id', 'target', 'references', 'local_or_sum', 'attribute', 'ex_or_im'],\n",
       "        num_rows: 1007\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story_name': 'magic-apples',\n",
       " 'context': 'he went from city to city , and sailed from country to country ; but it was a long journey , and lasted a year and a day , and even longer . but one day he got there after all . it was a sunday , and he found out that the king \\'s daughter was at church . then he sat himself down with his apples before the church door , and pretended to be a peddler . \" apples of damascus ! apples of damascus ! \" he cried . and sure enough , the king \\'s daughter came , and told her maidens to go and see what desirable things the peddler from abroad might have to offer . yes , he had apples of damascus . \" what do the apples give one ? \" asked the maiden . \" wisdom and beauty ! \" said the peddler , and the maiden bought .',\n",
       " 'qa_pairs': [{'question': \"why did the king's daughter send her maidens to the peddler ?\",\n",
       "   'answer': 'to go and see what desirable things the peddler from abroad might have to offer .'},\n",
       "  {'question': \"what happened after the king's daughter ate the third apple ?\",\n",
       "   'answer': 'her forehead was quite smooth again and she was even more beautiful than in days gone by .'},\n",
       "  {'question': 'who will the foreign doctor turn out to be ?',\n",
       "   'answer': 'the lad .'}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_story_qa_pairs(ds):\n",
    "    \"\"\"\n",
    "    Randomly samples three QA pairs from a randomly chosen story in the dataset.\n",
    "\n",
    "    Args:\n",
    "        ds (DatasetDict): A Hugging Face DatasetDict object containing 'train', 'validation', and 'test' splits.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing 'story_name', 'context', and a list of three QA pairs.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Randomly select a dataset split\n",
    "        split = random.choice(list(ds.keys()))\n",
    "        \n",
    "        # Get the dataset split\n",
    "        dataset_split = ds[split]\n",
    "        \n",
    "        # Randomly choose a story\n",
    "        story_names = list({row[\"story_name\"] for row in dataset_split})  # Convert set to list\n",
    "        story_name = random.choice(story_names)\n",
    "        \n",
    "        # Filter rows matching the chosen story\n",
    "        story_rows = [row for row in dataset_split if row[\"story_name\"] == story_name]\n",
    "        \n",
    "        # Ensure at least three QA pairs are available\n",
    "        if len(story_rows) >= 3:\n",
    "            # Randomly sample three QA pairs from the story rows\n",
    "            sampled_rows = random.sample(story_rows, 3)\n",
    "            \n",
    "            # Extract the context and QA pairs\n",
    "            context = sampled_rows[0][\"content\"]\n",
    "            qa_pairs = [{\"question\": row[\"question\"], \"answer\": row[\"answer\"]} for row in sampled_rows]\n",
    "            \n",
    "            # Return the result\n",
    "            return {\n",
    "                \"story_name\": story_name,\n",
    "                \"context\": context,\n",
    "                \"qa_pairs\": qa_pairs\n",
    "            }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = sample_story_qa_pairs(ds)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**Role: Moderator for a School Discussion**  \n",
    "\n",
    "You are moderating a group chat for primary and lower secondary school students. Your main goal is to create a welcoming and inclusive environment where every student feels encouraged to participate and share their ideas.  \n",
    "\n",
    "### Your Responsibilities:  \n",
    "1. **Start the Discussion:**  \n",
    "   - Introduce yourself and explain the purpose of the discussion.  \n",
    "   - Emphasize that everyone's input is important and will be treated with respect.  \n",
    "\n",
    "2. **Present the Topic:**  \n",
    "   - You will receive a passage and a related question.  \n",
    "   - Read or summarize the passage for the students, ensuring they understand it.  \n",
    "   - Present the question to the group and invite responses.  \n",
    "\n",
    "3. **Encourage Participation:**  \n",
    "   - Ensure every student has a chance to respond before revealing the correct answer.  \n",
    "   - Encourage quieter students with supportive prompts like, “What do you think, [name]?”  \n",
    "   - Maintain a respectful atmosphere where all ideas are valued.  \n",
    "\n",
    "4. **Provide Feedback:**  \n",
    "   - For incorrect answers, give constructive, age-appropriate feedback. Highlight positive aspects of their response and guide them gently toward the correct idea.  \n",
    "   - Celebrate correct answers with encouragement, such as, “That’s a great answer, [name]!”  \n",
    "\n",
    "5. **Ensure Equal Engagement:**  \n",
    "   - Balance the discussion by involving students who haven’t spoken and managing those who dominate the conversation.  \n",
    "\n",
    "### Special Note:  \n",
    "- Base your response on the chat history.  \n",
    "- If no response or action is required from you, reply only with \"NONE.\"\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
